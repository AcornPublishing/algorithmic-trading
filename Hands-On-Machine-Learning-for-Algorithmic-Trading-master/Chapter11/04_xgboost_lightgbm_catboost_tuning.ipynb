{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost, LightGBM and CatBoost Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "from random import shuffle\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost.callback import reset_learning_rate\n",
    "import lightgbm as lgb\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from itertools import product\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.expand_frame_repr', False)\n",
    "warnings.filterwarnings('ignore')\n",
    "idx = pd.IndexSlice\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change path to data store in `gbm_utils.py` if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you choose to compile any of the libraries with GPU support, amend the parameters in `gbm_params.py` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = Path('results')\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gbm_utils import format_time, get_data, get_one_hot_data, factorize_cats, get_holdout_set, OneStepTimeSeriesSplit\n",
    "from gbm_params import get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define declining learning rate schedule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate(n, ntot):\n",
    "    start_eta = 0.1\n",
    "    k = 8 / ntot\n",
    "    x0 = ntot / 1.8\n",
    "    return start_eta * (1 - 1 / (1 + np.exp(-k * (n - x0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntot = 10000\n",
    "x = np.asarray(range(ntot))\n",
    "pd.Series(learning_rate(x, ntot)).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validate GBM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBM = 'lightgbm'\n",
    "HOLDOUT = True\n",
    "FACTORS = True\n",
    "n_splits = 12\n",
    "\n",
    "result_key = f\"/{GBM}/{'factors' if FACTORS else 'dummies'}/results/2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Binary Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All libraries have their own data format to precompute feature statistics to accelerate the search for split points, as described previously. These can also be persisted to accelerate the start of subsequent training.\n",
    "\n",
    "The following code constructs binary train and validation datasets for each model to be used with the OneStepTimeSeriesSplit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The available options vary slightly: :\n",
    "- xgboost allows the use of all available threads\n",
    "- lightgbm explicitly aligns the quantiles that are created for the validation set with the training set\n",
    "- The catboost implementation needs feature columns identified using indices rather than labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(features, target, kfold, model='xgboost'):\n",
    "    cat_cols = ['year', 'month', 'age', 'msize', 'sector']\n",
    "    data = {}\n",
    "    for fold, (train_idx, test_idx) in enumerate(kfold.split(features)):\n",
    "        print(fold, end=' ', flush=True)\n",
    "        if model == 'xgboost':\n",
    "            data[fold] = {'train': xgb.DMatrix(label=target.iloc[train_idx],\n",
    "                                               data=features.iloc[train_idx],\n",
    "                                               nthread=-1),                     # use avail. threads\n",
    "                          'valid': xgb.DMatrix(label=target.iloc[test_idx],\n",
    "                                               data=features.iloc[test_idx],\n",
    "                                               nthread=-1)}\n",
    "        elif model == 'lightgbm':\n",
    "            train = lgb.Dataset(label=target.iloc[train_idx],\n",
    "                                data=features.iloc[train_idx],\n",
    "                                categorical_feature=cat_cols,\n",
    "                                free_raw_data=False)\n",
    "\n",
    "            # align validation set histograms with training set\n",
    "            valid = train.create_valid(label=target.iloc[test_idx],\n",
    "                                       data=features.iloc[test_idx])\n",
    "\n",
    "            data[fold] = {'train': train.construct(),\n",
    "                          'valid': valid.construct()}\n",
    "\n",
    "        elif model == 'catboost':\n",
    "            # get categorical feature indices\n",
    "            cat_cols_idx = [features.columns.get_loc(c) for c in cat_cols]\n",
    "            data[fold] = {'train': Pool(label=target.iloc[train_idx],\n",
    "                                        data=features.iloc[train_idx],\n",
    "                                        cat_features=cat_cols_idx),\n",
    "\n",
    "                          'valid': Pool(label=target.iloc[test_idx],\n",
    "                                        data=features.iloc[test_idx],\n",
    "                                        cat_features=cat_cols_idx)}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, features = get_data()\n",
    "if FACTORS:\n",
    "    X = factorize_cats(features)\n",
    "else:\n",
    "    X = get_one_hot_data(features)\n",
    "\n",
    "if HOLDOUT:\n",
    "    y, X, y_test, X_test = get_holdout_set(target=y,\n",
    "                                           features=X)\n",
    "\n",
    "    with pd.HDFStore('model_tuning.h5') as store:\n",
    "        key = f'{GBM}/holdout/'\n",
    "        if not any([k for k in store.keys() if k[1:].startswith(key)]):\n",
    "            store.put(key + 'features', X_test, format='t' if FACTORS else 'f')\n",
    "            store.put(key + 'target', y_test)\n",
    "\n",
    "cv = OneStepTimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "datasets = get_datasets(features=X, target=y, kfold=cv, model=GBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameter Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numerous hyperparameters are listed in [gbm_params.py](gbm_params.py). Each library has parameter settings to:\n",
    "- specify the overall objectives and learning algorithm\n",
    "- design the base learners\n",
    "- apply various regularization techniques\n",
    "- handle early stopping during training\n",
    "- enabling the use of GPU or parallelization on CPU\n",
    "\n",
    "The documentation for each library details the various parameters that may refer to the same concept, but which have different names across libraries. [This site](https://sites.google.com/view/lauraepp/parameters) highlights the corresponding parameters for xgboost and lightgbm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore the hyperparameter space, we specify values for key parameters that we would like to test in combination. The sklearn library supports RandomizedSearchCV to cross-validate a subset of parameter combinations that are sampled randomly from specified distributions. \n",
    "\n",
    "We will implement a custom version that allows us to leverage early stopping while monitoring the current best-performing combinations so we can abort the search process once satisfied with the result rather than specifying a set number of iterations beforehand.\n",
    "\n",
    "To this end, we specify a parameter grid according to each library's parameters as before, generate all combinations using the built-in Cartesian [product](https://docs.python.org/3/library/itertools.html#itertools.product) generator provided by the itertools library, and randomly shuffle the result. \n",
    "\n",
    "In the case of LightGBM, we automatically set `max_depth` as a function of the current num_leaves value, as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(\n",
    "        # common options\n",
    "        learning_rate=[.01, .1, .3],\n",
    "        # max_depth=list(range(3, 14, 2)),\n",
    "        colsample_bytree=[.8, 1],  # except catboost\n",
    "\n",
    "        # lightgbm\n",
    "        # max_bin=[32, 128],\n",
    "        num_leaves=[2 ** i for i in range(9, 14)],\n",
    "        boosting=['gbdt', 'dart'],\n",
    "        min_gain_to_split=[0, 1, 5],  # not supported on GPU\n",
    "\n",
    "        # xgboost\n",
    "        # booster=['gbtree', 'dart'],\n",
    "        # gamma=[0, 1, 5],\n",
    "\n",
    "        # catboost\n",
    "        # one_hot_max_size=[None, 2],\n",
    "        # max_ctr_complexity=[1, 2, 3],\n",
    "        # random_strength=[None, 1],\n",
    "        # colsample_bylevel=[.6, .8, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params = list(product(*param_grid.values()))\n",
    "n_models = len(all_params)\n",
    "shuffle(all_params)\n",
    "\n",
    "print('\\n# Models:', n_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function `run_cv()` implements cross-validation using the library-specific commands. The `train()` method also produces validation scores that are stored in the `scores` dictionary. \n",
    "\n",
    "When early stopping takes effect, the last iteration is also the best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cv(test_params, data, n_splits=10, gb_machine='xgboost'):\n",
    "    \"\"\"Train-Validate with early stopping\"\"\"\n",
    "    result = []\n",
    "    cols = ['rounds', 'train', 'valid']\n",
    "    for fold in range(n_splits):\n",
    "        train = data[fold]['train']\n",
    "        valid = data[fold]['valid']\n",
    "\n",
    "        scores = {}\n",
    "        if gb_machine == 'xgboost':\n",
    "            model = xgb.train(params=test_params,\n",
    "                              dtrain=train,\n",
    "                              evals=list(zip([train, valid], ['train', 'valid'])),\n",
    "                              verbose_eval=50,\n",
    "                              num_boost_round=250,\n",
    "                              early_stopping_rounds=25,\n",
    "                              evals_result=scores)\n",
    "\n",
    "            result.append([model.best_iteration,\n",
    "                           scores['train']['auc'][-1],\n",
    "                           scores['valid']['auc'][-1]])\n",
    "        elif gb_machine == 'lightgbm':\n",
    "            model = lgb.train(params=test_params,\n",
    "                              train_set=train,\n",
    "                              valid_sets=[train, valid],\n",
    "                              valid_names=['train', 'valid'],\n",
    "                              num_boost_round=250,\n",
    "                              early_stopping_rounds=25,\n",
    "                              verbose_eval=50,\n",
    "                              evals_result=scores)\n",
    "\n",
    "            result.append([model.current_iteration(),\n",
    "                           scores['train']['auc'][-1],\n",
    "                           scores['valid']['auc'][-1]])\n",
    "\n",
    "        elif gb_machine == 'catboost':\n",
    "            model = CatBoostClassifier(**test_params)\n",
    "            model.fit(X=train,\n",
    "                      eval_set=[valid],\n",
    "                      logging_level='Silent')\n",
    "\n",
    "            train_score = model.predict_proba(train)[:, 1]\n",
    "            valid_score = model.predict_proba(valid)[:, 1]\n",
    "            result.append([\n",
    "                model.tree_count_,\n",
    "                roc_auc_score(y_score=train_score, y_true=train.get_label()),\n",
    "                roc_auc_score(y_score=valid_score, y_true=valid.get_label())\n",
    "            ])\n",
    "\n",
    "    df = pd.DataFrame(result, columns=cols)\n",
    "    return (df\n",
    "            .mean()\n",
    "            .append(df.std().rename({c: c + '_std' for c in cols}))\n",
    "            .append(pd.Series(test_params)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code executes and exhaustive search over the parameter grid. The algorithms are already multithreaded so GridSearchCV does not add parallelization benefits. The below 'manual' implementation allows for more transparency during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "start = time()\n",
    "for n, test_param in enumerate(all_params, 1):\n",
    "    iteration = time()\n",
    "\n",
    "    cv_params = get_params(GBM)\n",
    "    cv_params.update(dict(zip(param_grid.keys(), test_param)))\n",
    "    if GBM == 'lightgbm':\n",
    "        cv_params['max_depth'] = int(ceil(np.log2(cv_params['num_leaves'])))\n",
    "\n",
    "    results[n] = run_cv(test_params=cv_params,\n",
    "                        data=datasets,\n",
    "                        n_splits=n_splits,\n",
    "                        gb_machine=GBM)\n",
    "    results.loc['time', n] = time() - iteration\n",
    "\n",
    "    if n > 1:\n",
    "        df = results[~results.eq(results.iloc[:, 0], axis=0).all(1)].T\n",
    "        if 'valid' in df.columns:\n",
    "            df.valid = pd.to_numeric(df.valid)\n",
    "            print('\\n')\n",
    "            print(df.sort_values('valid', ascending=False).head(5).reset_index(drop=True))\n",
    "\n",
    "    out = f'\\n\\tModel: {n} of {n_models} | '\n",
    "    out += f'{format_time(time() - iteration)} | '\n",
    "    out += f'Total: {format_time(time() - start)} | '\n",
    "    print(out + f'Remaining: {format_time((time() - start)/n*(n_models-n))}\\n')\n",
    "\n",
    "    with pd.HDFStore('model_tuning.h5') as store:\n",
    "        store.put(result_key, results.T.apply(pd.to_numeric, errors='ignore'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
